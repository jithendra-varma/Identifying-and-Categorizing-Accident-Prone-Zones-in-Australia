{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  loading the Required Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the CSV file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loaded from (https://data.sa.gov.au/data/dataset/road-crash-data/resource/78d24425-6c14-426e-8895-d414c2a12521)\n",
    "df = pd.read_csv('2019-2023_data_sa_as_at_20240913/2019-2023_DATA_SA_Crash.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering from 2019 to 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the Year column to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the DataFrame to include only the records from 2019 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Year'] >= 2019) & (df['Year'] <= 2022)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting 'Time' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time'], format='%I:%M %p').dt.strftime('%H:%M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a new column 'State' with all values set to 'SA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State'] = 'SA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Latitude and longitude Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the required second dataset (roadcrashes.csv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44420 entries, 0 to 44419\n",
      "Data columns (total 27 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   UNIQUE_LOC              44420 non-null  int64 \n",
      " 1   TOTAL_CRASHES           44420 non-null  int32 \n",
      " 2   CSE_PDO                 44420 non-null  int32 \n",
      " 3   CSE_INJ                 44420 non-null  int32 \n",
      " 4   CSE_FAT                 44420 non-null  int32 \n",
      " 5   CSE_SI                  44420 non-null  int32 \n",
      " 6   TOTAL_CASUALTIES        44420 non-null  int32 \n",
      " 7   TOTAL_FATALITIES        44420 non-null  int32 \n",
      " 8   TOTAL_SERIOUS_INJURIES  44420 non-null  int32 \n",
      " 9   CTY_REAR_END            44420 non-null  int32 \n",
      " 10  CTY_HIT_FIXED_OBJECT    44420 non-null  int32 \n",
      " 11  CTY_SIDE_SWIPE          44420 non-null  int32 \n",
      " 12  CTY_RIGHT_ANGLE         44420 non-null  int32 \n",
      " 13  CTY_HEAD_ON             44420 non-null  int32 \n",
      " 14  CTY_HIT_PEDESTRIAN      44420 non-null  int32 \n",
      " 15  CTY_ROLL_OVER           44420 non-null  int32 \n",
      " 16  CTY_RIGHT_TURN          44420 non-null  int32 \n",
      " 17  CTY_HIT_PARKED_VEHILE   44420 non-null  int32 \n",
      " 18  CTY_HIT_ANIMAL          44420 non-null  int32 \n",
      " 19  CTY_HIT_OBJECT_ON_ROAD  44420 non-null  int32 \n",
      " 20  CTY_LEFT_ROAD_OC        44420 non-null  int32 \n",
      " 21  CTY_OTHER               44420 non-null  int32 \n",
      " 22  CTY_UNKNOWN             44420 non-null  int32 \n",
      " 23  UTY_BICYCLE             44420 non-null  int32 \n",
      " 24  UTY_PEDESTRIAN          44420 non-null  int32 \n",
      " 25  LCO_NIGHT               44420 non-null  int32 \n",
      " 26  geometry                44420 non-null  object\n",
      "dtypes: int32(25), int64(1), object(1)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the GeoJSON file and convert it directly to a DataFrame\n",
    "gdf = gpd.read_file('RoadCrashes_geojson/RoadCrashes_GDA2020.geojson')\n",
    "df2 = pd.DataFrame(gdf)\n",
    "\n",
    "# Ensure UNIQUE_LOC is convertible to int32, then change its type\n",
    "df2['UNIQUE_LOC'] = df2['UNIQUE_LOC'].astype(int)\n",
    "\n",
    "# Change the data type of geometry column to object\n",
    "df2['geometry'] = df2['geometry'].astype(str)\n",
    "\n",
    "# Verify the changes\n",
    "df2.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50003 entries, 0 to 54166\n",
      "Data columns (total 35 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   REPORT_ID         50003 non-null  object \n",
      " 1   Stats Area        50003 non-null  object \n",
      " 2   Suburb            50003 non-null  object \n",
      " 3   Postcode          50003 non-null  int64  \n",
      " 4   LGA Name          49634 non-null  object \n",
      " 5   Total Units       50003 non-null  int64  \n",
      " 6   Total Cas         50003 non-null  int64  \n",
      " 7   Total Fats        50003 non-null  int64  \n",
      " 8   Total SI          50003 non-null  int64  \n",
      " 9   Total MI          50003 non-null  int64  \n",
      " 10  Year              50003 non-null  int64  \n",
      " 11  Month             50003 non-null  object \n",
      " 12  Day               50003 non-null  object \n",
      " 13  Time              50003 non-null  object \n",
      " 14  Area Speed        50003 non-null  int64  \n",
      " 15  Position Type     50003 non-null  object \n",
      " 16  Horizontal Align  50003 non-null  object \n",
      " 17  Vertical Align    50003 non-null  object \n",
      " 18  Other Feat        50003 non-null  object \n",
      " 19  Road Surface      50003 non-null  object \n",
      " 20  Moisture Cond     50003 non-null  object \n",
      " 21  Weather Cond      50003 non-null  object \n",
      " 22  DayNight          50003 non-null  object \n",
      " 23  Crash Type        50003 non-null  object \n",
      " 24  Unit Resp         50003 non-null  int64  \n",
      " 25  Entity Code       50003 non-null  object \n",
      " 26  CSEF Severity     50003 non-null  object \n",
      " 27  Traffic Ctrls     50003 non-null  object \n",
      " 28  DUI Involved      1671 non-null   object \n",
      " 29  Drugs Involved    1183 non-null   object \n",
      " 30  ACCLOC_X          49996 non-null  float64\n",
      " 31  ACCLOC_Y          49996 non-null  float64\n",
      " 32  UNIQUE_LOC        49997 non-null  float64\n",
      " 33  Crash Date Time   50003 non-null  object \n",
      " 34  State             50003 non-null  object \n",
      "dtypes: float64(3), int64(9), object(23)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging two df and df2 datasets on the common column \"UNIQUE_LOC\" to extract the geometry column from 2 dataset and adding it to first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df and df2 datasets on the common column \"UNIQUE_LOC\"\n",
    "df = pd.merge(df, df2[['UNIQUE_LOC', 'geometry']], on='UNIQUE_LOC', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the geometry column and getting the lattitude and longitude in new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_point(point):\n",
    "    # Convert point to string in case it's not\n",
    "    point = str(point)\n",
    "    # Remove the 'POINT (' and ')' parts and split by space\n",
    "    point = point.replace('POINT (', '').replace(')', '')\n",
    "    # Split the remaining string into longitude and latitude\n",
    "    parts = point.split()\n",
    "    # Check if there are two parts, to avoid errors\n",
    "    if len(parts) == 2:\n",
    "        lon, lat = parts\n",
    "        return float(lat), float(lon)\n",
    "    else:\n",
    "        return None, None  # Return None for both lat and lon if format is incorrect\n",
    "\n",
    "# Apply the parsing function to the 'geometry' column and create new columns\n",
    "df['latitude'], df['longitude'] = zip(*df['geometry'].apply(parse_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'LGA Name': 'LGA', 'Area Speed': 'speed limit'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Loc_type column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardizing the location types by mapping from Position_Type to loc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_types = [\n",
    "    \"Cross Road\", \"T-Junction\", \"Y-Junction\", \"Pedestrian Crossing\", \n",
    "    \"Multiple\", \"Rail Crossing\", \"Rail Xing\", \"Crossover\", \"Interchange\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loc_type'] = np.where(df['Position Type'].isin(intersection_types), 'Intersection', 'Midblock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming the column name DayNight to Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.rename(columns={'DayNight': 'Light_cond'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace the values 'Daylight' to 'Day' in the 'Light' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Light_cond'] = df['Light_cond'].replace('Daylight', 'Day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to standardize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column_names(columns):\n",
    "    # Strip whitespace, replace spaces with underscores, and convert to lowercase\n",
    "    standardized = [col.strip().replace(' ', '_').replace('-', '_').lower() for col in columns]\n",
    "    return standardized\n",
    "\n",
    "# Apply the function to the DataFrame's column names\n",
    "df.columns = standardize_column_names(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing columns (Keeping only the columns required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of standardized columns to keep\n",
    "columns_to_keep = [\n",
    "    'report_id',\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'time',\n",
    "    'state',\n",
    "    'stats_area',\n",
    "    'lga',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'loc_type',\n",
    "    'light_cond',\n",
    "    'weather_cond',\n",
    "    'speed_limit',\n",
    "    'csef_severity'\n",
    "]\n",
    "\n",
    "# Select only the specified columns\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows where 'lga', 'latitude','longitude' is an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.dropna(subset=['lga'])\n",
    "df = df.dropna(subset='latitude')\n",
    "df = df.dropna(subset='longitude')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows where 'weather' is 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['weather_cond'] != 'Unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the modified DataFrame to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('WorkSA1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
