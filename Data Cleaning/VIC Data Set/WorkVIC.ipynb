{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Required Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is downloaded from (https://discover.data.vic.gov.au/dataset/victoria-road-crash-data)\n",
    "gdf = gpd.read_file('VICTORIAN_ROAD_CRASH_DATA.geojson')\n",
    "vic_crash_data = pd.DataFrame(gdf)\n",
    "accident_location = pd.read_csv('ACCIDENT_LOCATION.csv')\n",
    "atmospheric_cond = pd.read_csv('ATMOSPHERIC_COND.csv')\n",
    "road_surface_cond = pd.read_csv('ROAD_SURFACE_COND.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets on 'ACCIDENT_NO'\n",
    "df = pd.merge(vic_crash_data, accident_location, on='ACCIDENT_NO', how='left')\n",
    "df = pd.merge(df, atmospheric_cond, on='ACCIDENT_NO', how='left')\n",
    "df = pd.merge(df, road_surface_cond, on='ACCIDENT_NO', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a column 'crash_date_time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175447 entries, 0 to 175446\n",
      "Data columns (total 67 columns):\n",
      " #   Column                  Non-Null Count   Dtype   \n",
      "---  ------                  --------------   -----   \n",
      " 0   ACCIDENT_NO             175447 non-null  object  \n",
      " 1   ACCIDENT_DATE           175447 non-null  object  \n",
      " 2   ACCIDENT_TIME           175447 non-null  object  \n",
      " 3   ACCIDENT_TYPE           175447 non-null  object  \n",
      " 4   DAY_OF_WEEK             175447 non-null  object  \n",
      " 5   DCA_CODE                175447 non-null  object  \n",
      " 6   DCA_CODE_DESCRIPTION    175447 non-null  object  \n",
      " 7   LIGHT_CONDITION         175447 non-null  object  \n",
      " 8   POLICE_ATTEND           175447 non-null  object  \n",
      " 9   ROAD_GEOMETRY           175447 non-null  object  \n",
      " 10  SEVERITY                175447 non-null  object  \n",
      " 11  SPEED_ZONE              175447 non-null  object  \n",
      " 12  RUN_OFFROAD             175447 non-null  object  \n",
      " 13  ROAD_NAME_x             175447 non-null  object  \n",
      " 14  ROAD_TYPE_x             175447 non-null  object  \n",
      " 15  ROAD_ROUTE_1_x          175447 non-null  int32   \n",
      " 16  LGA_NAME                175447 non-null  object  \n",
      " 17  DTP_REGION              175447 non-null  object  \n",
      " 18  LATITUDE                175447 non-null  float64 \n",
      " 19  LONGITUDE               175447 non-null  float64 \n",
      " 20  VICGRID_X               175447 non-null  float64 \n",
      " 21  VICGRID_Y               175447 non-null  float64 \n",
      " 22  TOTAL_PERSONS           175447 non-null  int32   \n",
      " 23  INJ_OR_FATAL            175447 non-null  int32   \n",
      " 24  FATALITY                175447 non-null  int32   \n",
      " 25  SERIOUSINJURY           175447 non-null  int32   \n",
      " 26  OTHERINJURY             175447 non-null  int32   \n",
      " 27  NONINJURED              175447 non-null  int32   \n",
      " 28  MALES                   175447 non-null  int32   \n",
      " 29  FEMALES                 175447 non-null  int32   \n",
      " 30  BICYCLIST               175447 non-null  int32   \n",
      " 31  PASSENGER               175447 non-null  int32   \n",
      " 32  DRIVER                  175447 non-null  int32   \n",
      " 33  PEDESTRIAN              175447 non-null  int32   \n",
      " 34  PILLION                 175447 non-null  int32   \n",
      " 35  MOTORCYCLIST            175447 non-null  int32   \n",
      " 36  UNKNOWN                 175447 non-null  int32   \n",
      " 37  PED_CYCLIST_5_12        175447 non-null  int32   \n",
      " 38  PED_CYCLIST_13_18       175447 non-null  int32   \n",
      " 39  OLD_PED_65_AND_OVER     175447 non-null  int32   \n",
      " 40  OLD_DRIVER_75_AND_OVER  175447 non-null  int32   \n",
      " 41  YOUNG_DRIVER_18_25      175447 non-null  int32   \n",
      " 42  NO_OF_VEHICLES          175444 non-null  float64 \n",
      " 43  HEAVYVEHICLE            175444 non-null  float64 \n",
      " 44  PASSENGERVEHICLE        175444 non-null  float64 \n",
      " 45  MOTORCYCLE              175444 non-null  float64 \n",
      " 46  PT_VEHICLE              175444 non-null  float64 \n",
      " 47  DEG_URBAN_NAME          174458 non-null  object  \n",
      " 48  SRNS                    46620 non-null   object  \n",
      " 49  RMA                     154753 non-null  object  \n",
      " 50  DIVIDED                 154753 non-null  object  \n",
      " 51  STAT_DIV_NAME           174445 non-null  object  \n",
      " 52  geometry                175447 non-null  geometry\n",
      " 53  NODE_ID                 175447 non-null  int64   \n",
      " 54  ROAD_ROUTE_1_y          175447 non-null  float64 \n",
      " 55  ROAD_NAME_y             175062 non-null  object  \n",
      " 56  ROAD_TYPE_y             172922 non-null  object  \n",
      " 57  ROAD_NAME_INT           174186 non-null  object  \n",
      " 58  ROAD_TYPE_INT           172729 non-null  object  \n",
      " 59  DISTANCE_LOCATION       175447 non-null  float64 \n",
      " 60  DIRECTION_LOCATION      175447 non-null  object  \n",
      " 61  ATMOSPH_COND            175447 non-null  int64   \n",
      " 62  ATMOSPH_COND_SEQ        175447 non-null  int64   \n",
      " 63  ATMOSPH_COND_DESC       175447 non-null  object  \n",
      " 64  SURFACE_COND            175447 non-null  int64   \n",
      " 65  SURFACE_COND_DESC       175447 non-null  object  \n",
      " 66  SURFACE_COND_SEQ        175447 non-null  int64   \n",
      "dtypes: float64(11), geometry(1), int32(21), int64(5), object(29)\n",
      "memory usage: 75.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(row):\n",
    "    date_str = str(row['ACCIDENT_DATE'])\n",
    "    time_str = str(row['ACCIDENT_TIME']).zfill(6)  # Ensure time is in hhmmss format\n",
    "    \n",
    "    year = int(date_str[:4])\n",
    "    month = datetime.strptime(date_str[4:6], '%m').strftime('%B')  # Convert month number to month name\n",
    "    day = row['DAY_OF_WEEK']\n",
    "    \n",
    "    hour = int(time_str[:2])\n",
    "    minute = int(time_str[2:4])\n",
    "    \n",
    "    return year, month, day, f\"{hour:02}:{minute:02}\"\n",
    "\n",
    "# Apply function to each row\n",
    "df['year'], df['month'], df['day'], df['time'] = zip(*df.apply(convert_to_datetime, axis=1))\n",
    "\n",
    "# Drop the original columns if needed\n",
    "df.drop(columns=['ACCIDENT_DATE', 'ACCIDENT_TIME', 'DAY_OF_WEEK'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['year'] >= 2019) & (df['year'] <= 2022)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename the 'ACCIDENT_NO' column to 'report_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'ACCIDENT_NO': 'report_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a new column 'State' with all values set to 'VIC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State'] = 'VIC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the column 'Stats Area'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Rename the column\n",
    "df.rename(columns={'DEG_URBAN_NAME': 'stats_area'}, inplace=True)\n",
    "\n",
    "# Step 2: Replace specific values\n",
    "area_mapping = {\n",
    "    'MELBOURNE_CBD': '1 City',\n",
    "    'MELB_URBAN': '2 Metropolitan',\n",
    "    'SMALL_CITIES': '2 Metropolitan',\n",
    "    'LARGE_PROVINCIAL_CITIES': '2 Metropolitan',\n",
    "    'RURAL_VICTORIA': '3 Country',\n",
    "    'TOWNS': '3 Country',\n",
    "    'SMALL_TOWNS': '3 Country'\n",
    "}\n",
    "df['stats_area'] = df['stats_area'].replace(area_mapping)\n",
    "df = df.dropna(subset=['stats_area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the 'lga' column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Rename the column\n",
    "df.rename(columns={'LGA_NAME': 'lga'}, inplace=True)\n",
    "\n",
    "# Dropping blank data\n",
    "df = df.dropna(subset=['lga'])\n",
    "df = df[df['lga'] != ' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the speed_limit column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "df.rename(columns={'SPEED_ZONE': 'speed_limit'}, inplace=True)\n",
    "\n",
    "# Filter out 'Unknown' speed limits first\n",
    "df = df[~df['speed_limit'].isin(['Not known', 'Camping grounds or off road', 'Other speed limit'])]\n",
    "\n",
    "# Remove ' km/h' and replace non-digit characters\n",
    "df['speed_limit'] = df['speed_limit'].str.replace(' km/h', '').str.replace(r'\\D', '', regex=True)\n",
    "\n",
    "# Convert 'speed_limit' to integer\n",
    "df['speed_limit'] = df['speed_limit'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the 'Loc_type' and 'Location' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_location(row):\n",
    "    if row['DISTANCE_LOCATION'] == 0:\n",
    "        loc_type = 'Intersection'\n",
    "        location = f\"{row['ROAD_NAME_x']} {row['ROAD_TYPE_x']} & {row['ROAD_NAME_INT']} {row['ROAD_TYPE_INT']}\"\n",
    "    else:\n",
    "        loc_type = 'Midblock'\n",
    "        location = f\"{row['ROAD_NAME_x']} {row['ROAD_TYPE_x']}\"\n",
    "    return pd.Series([location, loc_type])\n",
    "\n",
    "# Apply the function to each row and create new columns\n",
    "df[['Location', 'loc_type']] = df.apply(classify_location, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating weather_cond column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Rename the column\n",
    "df.rename(columns={'ATMOSPH_COND_DESC': 'weather_cond'}, inplace=True)\n",
    "\n",
    "# Step 2: Replace specific values\n",
    "df['weather_cond'] = df['weather_cond'].replace({\n",
    "    'Clear': 'Not Raining',\n",
    "    'Dust': 'Not Raining',\n",
    "    'Fog': 'Not Raining',\n",
    "    'Smoke': 'Not Raining',\n",
    "    'Strong winds': 'Not Raining',\n",
    "    'Snowing': 'Raining'\n",
    "})\n",
    "\n",
    "# Step 3: Remove rows with 'Unknown'\n",
    "df = df[df['weather_cond'] != 'Not known']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the light_cond column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102125      Day\n",
      "102126    Night\n",
      "102127    Night\n",
      "102129      Day\n",
      "102130    Night\n",
      "Name: light_cond, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "df = df.copy()\n",
    "\n",
    "# Step 2: Rename the column safely\n",
    "df.rename(columns={'LIGHT_CONDITION': 'light_cond'}, inplace=True)\n",
    "\n",
    "# Step 3: Replace specific values in 'light_cond'\n",
    "df.loc[df['light_cond'] == 'Dusk/Dawn', 'light_cond'] = 'Day'\n",
    "\n",
    "# Step 4: Replace values containing \"Dark\" with \"Night\"\n",
    "df.loc[df['light_cond'].str.contains(\"Dark\", na=False), 'light_cond'] = \"Night\"\n",
    "\n",
    "# Step 5: Remove rows with 'Unknown' light conditions\n",
    "df = df[df['light_cond'] != 'Unk.']\n",
    "\n",
    "# Verify changes\n",
    "print(df['light_cond'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the csef_severity column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Rename the column\n",
    "df.rename(columns={'SEVERITY': 'csef_severity'}, inplace=True)\n",
    "\n",
    "# Step 2: Replace specific values\n",
    "df['csef_severity'] = df['csef_severity'].replace({\n",
    "    'Fatal accident': '3: Fatal',\n",
    "    'Non injury accident': '1: PDO',\n",
    "    'Other injury accident': '1: PDO',\n",
    "    'Serious injury accident': '2: INJ'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to standardize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column_names(columns):\n",
    "    # Strip whitespace, replace spaces with underscores, and convert to lowercase\n",
    "    standardized = [col.strip().replace(' ', '_').replace('-', '_').lower() for col in columns]\n",
    "    return standardized\n",
    "\n",
    "# Apply the function to the DataFrame's column names\n",
    "df.columns = standardize_column_names(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing columns (Keeping only the columns required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of standardized columns to keep\n",
    "columns_to_keep = [\n",
    "    'report_id',\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'time',\n",
    "    'state',\n",
    "    'stats_area',\n",
    "    'lga',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'loc_type',\n",
    "    'location',\n",
    "    'light_cond',\n",
    "    'weather_cond',\n",
    "    'speed_limit',\n",
    "    'csef_severity'\n",
    "]\n",
    "\n",
    "# Select only the specified columns\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the modified DataFrame to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Final_VIC.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
