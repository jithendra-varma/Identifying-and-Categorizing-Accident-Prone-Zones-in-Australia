{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset into a DataFrame with the specified encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Crash ID         Degree of crash Degree of crash - detailed  \\\n",
      "0   1151002  Non-casualty (towaway)     Non-casualty (towaway)   \n",
      "1   1158000                   Fatal                      Fatal   \n",
      "2   1158001                   Fatal                      Fatal   \n",
      "3   1158002                   Fatal                      Fatal   \n",
      "4   1158515                   Fatal                      Fatal   \n",
      "\n",
      "   Reporting year  Year of crash Month of crash Day of week of crash  \\\n",
      "0            2018           2018       February             Thursday   \n",
      "1            2018           2018        January               Monday   \n",
      "2            2018           2018        January               Monday   \n",
      "3            2018           2018        January               Monday   \n",
      "4            2018           2018        January              Tuesday   \n",
      "\n",
      "  Two-hour intervals Street of crash Street type  ...  \\\n",
      "0      06:00 - 07:59       SACKVILLE          ST  ...   \n",
      "1      00:01 - 01:59         BRUNKER          RD  ...   \n",
      "2      08:00 - 09:59        CLARENCE         WAY  ...   \n",
      "3      02:00 - 03:59         RAILWAY          RD  ...   \n",
      "4      20:00 - 21:59       CHRISTINA          RD  ...   \n",
      "\n",
      "            DCA - description DCA supplement     First impact type  \\\n",
      "0  Manov - Reverse in traffic            NaN           Other angle   \n",
      "1            On path - Parked            NaN           Other angle   \n",
      "2      Off left bend into obj          Right      Vehicle - Object   \n",
      "3        Ped - On carriageway            NaN  Vehicle - Pedestrian   \n",
      "4              Ped - Far side            NaN  Vehicle - Pedestrian   \n",
      "\n",
      "         Key TU type                   Other TU type  \\\n",
      "0  Car (sedan/hatch)               Car (sedan/hatch)   \n",
      "1  Car (sedan/hatch)  Light truck utility(from 2018)   \n",
      "2  Car (sedan/hatch)                             NaN   \n",
      "3  Car (sedan/hatch)                      Pedestrian   \n",
      "4  Car (sedan/hatch)                      Pedestrian   \n",
      "\n",
      "   No. of traffic units involved No. killed No. seriously injured  \\\n",
      "0                              3          0                     0   \n",
      "1                              2          1                     2   \n",
      "2                              1          1                     0   \n",
      "3                              2          1                     0   \n",
      "4                              2          1                     0   \n",
      "\n",
      "  No. moderately injured  No. minor-other injured  \n",
      "0                      0                        0  \n",
      "1                      0                        0  \n",
      "2                      0                        0  \n",
      "3                      0                        0  \n",
      "4                      0                        0  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data is loaded from (https://opendata.transport.nsw.gov.au/dataset/nsw-crash-data)\n",
    "# Load the dataset from an Excel file (.xlsx format)\n",
    "# Specify the sheet name if needed, otherwise it defaults to the first sheet\n",
    "df = pd.read_excel('nsw_road_crash_data_2018-2022_crash.xlsx', sheet_name='Crash Data Table')  \n",
    "# Display the first few rows to verify the data loaded correctly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the Year column to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df['Year of crash'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the DataFrame to include only the records from 2019 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Year'] >= 2019) & (df['Year'] <= 2022)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows where 'time' is 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Two-hour intervals'] != 'Unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the 'crash_date_time' and 'day' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.rename(columns={\n",
    "    'Month of crash': 'month',\n",
    "    'Day of week of crash': 'day',\n",
    "    'Two-hour intervals': 'time'\n",
    "}, inplace=True)\n",
    "\n",
    "# Function to extract center time from 'Two-hour intervals'\n",
    "def extract_start_time(interval):\n",
    "    if 'Midnight' in interval:\n",
    "        return '00:00'  # Midnight as 00:00 in 24-hour format\n",
    "    else:\n",
    "        start_time, _ = interval.split(' - ')\n",
    "        return start_time.strip()  # Return start time without leading or trailing spaces\n",
    "\n",
    "# Apply function to 'time' column\n",
    "df['time'] = df['time'].apply(extract_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the 'day of week of crash' to 'day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.rename(columns={'Crash ID':'report_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new column 'State' with all values set to 'NSW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State'] = 'NSW'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the 'stats_area' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_area(conurbation):\n",
    "    if conurbation == 'Syd-Newc-Woll Gtr conurbation':\n",
    "        return '1 City'\n",
    "    elif conurbation == 'Rest of NSW - Urban':\n",
    "        return '2 Metropolitan'\n",
    "    elif conurbation in ('Rest of NSW - Rural'):\n",
    "        return '3 Country'\n",
    "    else:\n",
    "        return 'Other'  # In case there are other unaccounted values\n",
    "\n",
    "# Apply the function to the 'Conurbation 1' column to create a new 'area_type' column\n",
    "df['stats_area'] = df['Conurbation 1'].apply(classify_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows where 'stats_area' is 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['stats_area'] != 'Other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the 'Loc_type' and 'Location' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_location(row):\n",
    "    if row['Distance'] == 0:\n",
    "        loc_type = 'Intersection'\n",
    "        location = f\"{row['Street of crash']} {row['Street type']} & {row['Identifying feature']} {row['Identifying feature type']}\"\n",
    "    else:\n",
    "        loc_type = 'Midblock'\n",
    "        location = f\"{row['Street of crash']} {row['Street type']}\"\n",
    "    return pd.Series([location, loc_type])\n",
    "\n",
    "# Apply the function to each row and create new columns\n",
    "df[['Location', 'loc_type']] = df.apply(classify_location, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the 'light_cond' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Rename the column\n",
    "df.rename(columns={'Natural lighting': 'light_cond'}, inplace=True)\n",
    "\n",
    "# Step 2: Replace specific values\n",
    "df['light_cond'] = df['light_cond'].replace({\n",
    "    'Darkness': 'Night',\n",
    "    'Dawn': 'Day',\n",
    "    'Daylight': 'Day',\n",
    "    'Dusk': 'Day'\n",
    "})\n",
    "\n",
    "# Step 3: Remove rows with 'Unknown'\n",
    "df = df[df['light_cond'] != 'Unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the 'weather_cond' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Rename the column\n",
    "df.rename(columns={'Weather': 'weather_cond'}, inplace=True)\n",
    "\n",
    "# Step 2: Replace specific values\n",
    "df['weather_cond'] = df['weather_cond'].replace({\n",
    "    'Fine': 'Not Raining',\n",
    "    'Fog or mist': 'Not Raining',\n",
    "    'Overcast': 'Not Raining',\n",
    "    'Other': 'Raining',\n",
    "    'Raining': 'Raining',\n",
    "    'Snowing': 'Raining'\n",
    "})\n",
    "\n",
    "# Step 3: Remove rows with 'Unknown'\n",
    "df = df[df['weather_cond'] != 'Unknown']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the speed limit column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out 'Unknown' speed limits first\n",
    "df = df[df['Speed limit'] != 'Unknown']\n",
    "\n",
    "# Convert 'Speed limit' to integer values after removing ' km/h'\n",
    "df['Speed limit'] = df['Speed limit'].str.replace(' km/h', '').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the csef_severity column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Rename the column\n",
    "df.rename(columns={'Degree of crash - detailed': 'csef_severity'}, inplace=True)\n",
    "\n",
    "# Step 2: Replace specific values\n",
    "df['csef_severity'] = df['csef_severity'].replace({\n",
    "    'Fatal': '4: Fatal',\n",
    "    'Non-casualty (towaway)': '1: PDO',\n",
    "    'Minor/Other Injury': '2: MI',\n",
    "    'Moderate Injury': '2: MI',\n",
    "    'Serious Injury': '3: SI'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to standardize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column_names(columns):\n",
    "    # Strip whitespace, replace spaces with underscores, and convert to lowercase\n",
    "    standardized = [col.strip().replace(' ', '_').replace('-', '_').lower() for col in columns]\n",
    "    return standardized\n",
    "\n",
    "# Apply the function to the DataFrame's column names\n",
    "df.columns = standardize_column_names(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing columns (Keeping only the columns required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of standardized columns to keep\n",
    "columns_to_keep = [\n",
    "    'report_id',\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'time',\n",
    "    'state',\n",
    "    'stats_area',\n",
    "    'lga',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'loc_type',\n",
    "    'location',\n",
    "    'light_cond',\n",
    "    'weather_cond',\n",
    "    'speed_limit',\n",
    "    'csef_severity'\n",
    "]\n",
    "\n",
    "# Select only the specified columns\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the modified DataFrame to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Final_NSW.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
